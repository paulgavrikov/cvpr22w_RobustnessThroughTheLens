{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20220225_131619_robustness'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID=\"20220225_131619_robustness\"\n",
    "ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf /data/output/$ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir /data/output/$ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp meta.csv /data/output/$ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 312K\n",
      "drwxr-xr-x. 2 root root 4.0K Feb 25 13:24 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
      "-rw-r--r--. 1 root root   56 Feb 25 13:24 pipeline_log.txt\n",
      "-rw-r--r--. 1 root root  910 Feb 25 13:24 20220225_132319_extract.log\n",
      "drwxr-xr-x. 3 root root 4.0K Feb 25 13:23 \u001b[01;34m..\u001b[0m/\n",
      "-rw-r--r--. 1 root root 284K Feb 25 13:22 20220225_132136_create.log\n",
      "-rw-r--r--. 1 root root  700 Feb 25 13:20 20220225_132027_create.log\n",
      "-rw-r--r--. 1 root root 7.3K Feb 25 13:18 20220225_131809_create.log\n"
     ]
    }
   ],
   "source": [
    "ls -lath /data/output/$ID/logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-25 13:23:19,028 [INFO]  starting extraction Namespace(dir='/data/output/20220225_131619_full/', filter_info_output_file='/data/output/20220225_131619_full/filterinfo.csv', filter_output_file='/data/output/20220225_131619_full/', filter_shape=(3, 3), first_convs_only=False, meta_file=<_io.TextIOWrapper name='/data/output/20220225_131619_full/datastorage.meta.csv' mode='r' encoding='UTF-8'>)\n",
      "2022-02-25 13:23:19,031 [INFO]  loading chunk /data/output/20220225_131619_full/datastorage.0000.pkl\n",
      "2022-02-25 13:23:34,475 [INFO]  loaded ... processing\n",
      "2022-02-25 13:23:52,473 [INFO]  finished chunk /data/output/20220225_131619_full/datastorage.0000.pkl with 117 models\n",
      "2022-02-25 13:23:54,926 [INFO]  writing filter info dataframe: /data/output/20220225_131619_full/filterinfo.csv\n",
      "2022-02-25 13:23:54,941 [INFO]  writing filters /data/output/20220225_131619_full/\n",
      "2022-02-25 13:24:41,766 [INFO]  finished\n"
     ]
    }
   ],
   "source": [
    "cat  /data/output/$ID/logs/20220225_132319_extract.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 117/117 [01:39<00:00,  1.18it/s]\n"
     ]
    }
   ],
   "source": [
    "!cd onnxzoo2filterdb && python3 create_filter_storage.py /ssd1/robustness_onnx_zoo/ /data/output/$ID/meta.csv /data/output/$ID/ --split_after 1000 --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-25 13:23:19,028 [INFO]  starting extraction Namespace(dir='/data/output/20220225_131619_full/', filter_info_output_file='/data/output/20220225_131619_full/filterinfo.csv', filter_output_file='/data/output/20220225_131619_full/', filter_shape=(3, 3), first_convs_only=False, meta_file=<_io.TextIOWrapper name='/data/output/20220225_131619_full/datastorage.meta.csv' mode='r' encoding='UTF-8'>)\n",
      "2022-02-25 13:23:19,031 [INFO]  loading chunk /data/output/20220225_131619_full/datastorage.0000.pkl\n",
      "2022-02-25 13:23:34,475 [INFO]  loaded ... processing\n",
      "2022-02-25 13:23:52,473 [INFO]  finished chunk /data/output/20220225_131619_full/datastorage.0000.pkl with 117 models\n",
      "2022-02-25 13:23:54,926 [INFO]  writing filter info dataframe: /data/output/20220225_131619_full/filterinfo.csv\n",
      "2022-02-25 13:23:54,941 [INFO]  writing filters /data/output/20220225_131619_full/\n",
      "2022-02-25 13:24:41,766 [INFO]  finished\n"
     ]
    }
   ],
   "source": [
    "!cd onnxzoo2filterdb && python3 extract_filters.py /data/output/$ID/ /data/output/$ID/datastorage.meta.csv /data/output/$ID/filterinfo.csv /data/output/$ID/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"Created by processing_pipeline.ipynb on\" $timestamp >> /data/output/$ID/logs/pipeline_log.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tables ...\n",
      " df_filter_info\n",
      " df_meta\n",
      " df_meta_spreadsheets\n",
      " merging meta\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_91636/73617082.py:11: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['filter_ids', 'model', 'path', 'producer', 'Name', 'Paper',\n",
      "       'Tracer Warning', 'Selection', 'Robust', 'Network', 'Backbone',\n",
      "       'Framework', 'Pretraining-Dataset', 'Training-Dataset',\n",
      "       'Visual Category', 'Visual Category_micro', 'Precision', 'Task'],\n",
      "      dtype='object')]\n",
      "\n",
      "  fid_by_mid_with_meta.to_hdf(os.path.join(root_path, dataset_id, \"dataset.h5\"), \"meta\")\n"
     ]
    }
   ],
   "source": [
    "from onnxzoo2filterdb.filter_dataset import FilterDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "root_path = \"/data/output\"\n",
    "dataset_id = ID\n",
    "filter_dataset = FilterDataset(dataset_id, root=root_path, filters=False)\n",
    "fid_by_mid_with_meta = filter_dataset.df_filter_info.groupby([filter_dataset.df_filter_info.index, filter_dataset.df_filter_info.conv_depth, filter_dataset.df_filter_info.conv_depth_norm, filter_dataset.df_filter_info.layer_id]).filter_ids.apply(lambda x: np.hstack(x)).to_frame().join(filter_dataset.df_fused_meta, on=[\"model_id\"])\n",
    "fid_by_mid_with_meta[\"filter_ids\"] = fid_by_mid_with_meta[\"filter_ids\"].apply(lambda x: f\"{x[0]}:{x[-1]}\")\n",
    "fid_by_mid_with_meta.to_hdf(os.path.join(root_path, dataset_id, \"dataset.h5\"), \"meta\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
